---
layout: post
date: 2022-05-9 14:00
created_date: 2022-05-9 14:00
title: "[Paper] 2204 DiffCSE: Difference-based Contrastive Learning for Sentence Embeddings"
author: Yung-Sung Chuang, Yoon Kim et al.
description: "DiffCSE: Difference-based Contrastive Learning for Sentence Embeddings"
comments: true
math: true
category: 
- Paper
tags:
- NLP
- SimCSE
- DiffCSE
- Contrastive Learning
---

DiffCSE ë¦¬ë·°
<!--more-->

# Abstract
_We propose **DiffCSE, an unsupervised contrastive learning framework** for learning sentence embeddings. DiffCSE learns sentence embeddings that are **sensitive to the difference between the original sentence and an edited sentence**, where the edited sentence is obtained by stochastically masking out the original sentence and then sampling from a masked language model. We show that DiffSCE is an instance of equivariant contrastive learning (Dangovski et al., 2021), which generalizes contrastive learning and learns representations that are insensitive to certain types of augmentations and sensitive to other â€œharmfulâ€ types of augmentations. Our experiments show that DiffCSE achieves state-of-the-art results among unsupervised sentence representation learning methods, outperforming unsupervised SimCSE1 by 2.3 absolute points on semantic textual similarity tasks_

# Introduction
- Contrastive learning uses **multiple augmentations** on a single datum to construct positive pairs whose representations are trained to be more similar to one another than negative pairs.
- **SimCSE** finds that constructing positive pairs via a **simple dropout-based augmentation** works much better than more complex augmentations such as word deletions or replacements based on synonyms or masked language models.
` This is because direct augmentations on the input often change the meaning of the sentence.`
- We propose to learn sentence representations that are **aware of, but not necessarily invariant to, such direct surface-level augmentations.**
- This is an **instance of equivariant contrastive learning**, which improves vision representation learning by using a contrastive loss on insensitive image transformations (e.g., grayscale) and a prediction loss on sensitive image transformations (e.g., rotations).
- We operationalize **equivariant contrastive learning on sentences** by using **dropout-based augmentation** as the insensitive transformation (as in SimCSE (Gao et al., 2021)) and **MLM-based word replacement** as the sensitive transformation. 
- We conduct experiments on **7 semantic textual similarity tasks (STS) and 7 transfer tasks from SentEval**
- DiffCSE approach can achieve around 2.3% absolute improvement over SimCSE.

# Related Work
## Equivariant(ë“±ë³€) Contrastive Learning
- **Invariant Contrastive Learning**
  - ì…ë ¥ xì— ëŒ€í•˜ì—¬, f(T(x)) = f(x) ê°€ ë˜ë„ë¡ fë¥¼ í›ˆë ¨
  - Transformationì— invariant í•œ ê°’ì„ ì¶œë ¥í•˜ë„ë¡ í•™ìŠµ. **insensitive to Transformation(G)**
  - ![image](https://user-images.githubusercontent.com/18374514/167547477-16a66a22-2cf2-4c1b-b8a6-2fd90842fda4.png)
  - ê·¸ëŸ¬ë‚˜ Transformationì— ë”°ë¼ì„œ Semantic í•œ ì •ë³´ê°€ ë³€ê²½ë˜ëŠ” ê²½ìš°ê°€ í—ˆë‹¤í•˜ê¸° ë•Œë¬¸ì— ë‹¨ì ì´ ìˆëŠ” í•™ìŠµë²•
  - Understanding the role of **input transformations is crucial** for successful contrastive learning.
  - But some of revealed transformations are shown to be harmful for CL.
    - Ex) image rotation or MLM in NLP
    - SimCSEì— ë‚˜ì™€ ìˆëŠ” MLMì„ Augmentation ë°©ì‹ìœ¼ë¡œ ì‚¬ìš©í–ˆì„ ê²½ìš°ì˜ ê²°ê³¼
    - ![image](https://user-images.githubusercontent.com/18374514/167335228-5ce32aea-97c9-4878-b397-57b60c5f627e.png)

- **Equivariant Contrastive Learning**
  - ì…ë ¥ xì— ëŒ€í•˜ì—¬, f(T(x)) = T'(f(x)) ê°€ ë˜ë„ë¡ fë¥¼ í›ˆë ¨, T'ì´ identity functionì´ë©´ ICLê³¼ ë™ì¼
  - Tì™€ T'ì€ íŒŒë¼ë¯¸í„°ê°€ ì—†ëŠ” fixed transformation
  - ë”°ë¼ì„œ ì € ì‹ì´ ì™„ì„±ë˜ë ¤ë©´ fê°€ Tì— êµ‰ì¥íˆ Sensitiveí•˜ê²Œ í•™ìŠµì´ ë˜ì–´ì•¼ í•¨.
  - ì´ê²ƒì„ **equivariance to Transformation(G)**ë¼ í‘œí˜„í•¨
`Insensitive, SensitiveëŠ” ê·¸ëƒ¥ ìˆì–´ ë³´ì´ê¸° ìœ„í•œ í‘œí˜„ ë°©ì‹ì¼ ë¿ì¸ ê²ƒ ê°™ë‹¤ëŠ” ìƒê°ì´.. ì‚¬ì‹¤ ICLì—ì„œë„ fê°€ Tì— ìƒê´€ì—†ì´ ë™ì¼í•œ ê°’ì„ ë‚´ë ¤ë©´ Tì— insensitiveí•˜ê¸°ë§Œ í•˜ë©´ ë˜ëŠ”ê±´ ì•„ë‹Œ ê²ƒ ê°™ì€ë°..`
  - equivariant CL ì´ë¯¸ì§€ ![image](https://user-images.githubusercontent.com/18374514/167349581-e5424897-1fb5-4839-874c-bb0e3a57fd11.png)
  ![image](https://user-images.githubusercontent.com/18374514/167547516-4f5b93c6-6002-460e-9099-ed9d4b447b09.png)

# Difference-based Contrastive Learning
- DiffCSEëŠ” ê²°êµ­ Equivariant CL í˜ì´í¼ì˜ NLP ë²„ì „ì´ë‹¤. ECLì—ì„œì²˜ëŸ¼ Hybrid ë°©ì‹ìœ¼ë¡œ CLì„ ì§„í–‰(ICL+ECL). 
- ![image](https://user-images.githubusercontent.com/18374514/167334643-80ad1e39-674b-463d-9114-8e4fcc71faa8.png)
- ìœ„ ê·¸ë¦¼ì˜ ì™¼ìª½ì—ì„œ ë³´ë“¯ì´, SimCSEì˜ Loss ë˜í•œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
- ![image](https://user-images.githubusercontent.com/18374514/167548059-cd176bbe-45f7-4aff-9e0b-5d799260c84d.png)
- **Sentence Encoderë¡œëŠ” BERT, RoBERTa** ë“± ì‚¬ìš©
- ì˜¤ë¥¸ìª½ì€ **Conditional ELECTRA ì‚¬ìš©**
  - input xì— random masking(30%)ì„ í•´ì„œ X'ì„ ë§Œë“¦.
  - Mask ëœ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•´ì„œ ìƒˆë¡œìš´ X''ì„ ë§Œë“¤ì–´ë‚¼ GeneratorëŠ” Fixed Pretrained LMì‚¬ìš©
  - ì›ë˜ ELECTRA Paperì—ì„œì²˜ëŸ¼ GeneratorëŠ” ë„ˆë¬´ MASK ë‹¨ì–´ë¥¼ ì˜ ìœ ì¶”í•  í•„ìš”ê°€ ì—†ìœ¼ë¯€ë¡œ **DistilBERT**ë¥¼ ì‚¬ìš©
  - DiscriminatorëŠ” X''ì˜ ê° tokenë“¤ì´ Generatorì— ì˜í•´ replace ëœê±´ì§€ ì›ë˜ Tokenì¸ì§€ ë§ì¶”ëŠ” binary classificaiton ë¬¸ì œë¥¼ í•™ìŠµ(Replace Token Detection)
  - ![image](https://user-images.githubusercontent.com/18374514/167551606-0a466562-4478-4cb0-b200-205e05086214.png)
  - ê·¸ë˜ì„œ Total LossëŠ”
    - ![image](https://user-images.githubusercontent.com/18374514/167551864-73afc4c4-6f60-4200-9117-a3f2e135a271.png)
    - **ìµœì  lambdaëŠ” 0.005**
  - **ê·¼ë° ì™œ Conditional ì´ëƒ?**
    - ì™¼ìª½ì˜ SentenceEncoderì—ì„œ ë„˜ì–´ì˜¤ëŠ” **sentence representation h = f(x)**ë¥¼ ì´ìš©í•´ì„œ RTDë¥¼ í•˜ê¸° ë•Œë¬¸
    - **ì´ **h** ê°€ RTDë¥¼ ì˜ í•  ìˆ˜ ìˆë„ë¡ ì¶©ë¶„íˆ informative í•´ ì§€ë„ë¡ fê°€ í•™ìŠµì´ ë˜ëŠ” ê²ƒì´ ì¤‘ìš”**
    - This approach essentially makes the conditional discriminator perform a **â€œdiff operationâ€,** hence the name DiffCSE.
- Genertor GëŠ” Fixë˜ê³  SentenceEncoder f ì™€ Discriminator DëŠ” í•™ìŠµë¨. 
- í•™ìŠµ í›„, **Sentence Embeddingì„ ë½‘ì•„ë‚¼ ë•ŒëŠ” fë§Œ ì‚¬ìš©**

# Experimants
- SimCSEì™€ ëŒ€ì²´ì ìœ¼ë¡œ ë¹„ìŠ·
- Sentence Embeddingìœ¼ë¡œëŠ” [CLS]ë¥¼ ì“°ë˜, **MLPì™€ BatchNorm**ì„ í†µê³¼ì‹œì¼œì„œ ì‚¬ìš©
  - ![image](https://user-images.githubusercontent.com/18374514/167557696-d010404c-9b0d-4f0c-aa5b-01abcd32a8db.png)

## Data
- Unsupervised Learning Training Data
  - Random 1M Wiki ë¬¸ì¥
- Evaluation
  - 7 STS and 7 Transfer Task Dataset
 
## Results
- ![image](https://user-images.githubusercontent.com/18374514/167558318-f1ea357a-4573-4589-a3d8-36dca6616b14.png)
- ![image](https://user-images.githubusercontent.com/18374514/167558802-d983294b-2650-4560-8406-578031e65a37.png)

## Ablation Task
**1) Removing CL**
  -  CL ì—†ì´ RTDë§Œ í•˜ê²Œ ë˜ë©´, STS-B ì ìˆ˜ëŠ” 30%ê°€ ë–¨ì–´ì§€ì§€ë§Œ Transfer TaskëŠ” ì˜¤ì§ 2%ë§Œ í•˜ë½. 
  - This result shows that it is important to have insensitive and sensitive attributes that **exist together in the representation space.**

**2) Next Sentence vs Same Sentence**
  - ELECTRAì—ëŠ” Same Sentenceê°€ ì•„ë‹ˆë¼ Next Sentenceë¥¼ ë„£ìŒ(ì´ëŸ¬ë©´ Diff operationì€ ì‚¬ë¼ì§)
  - ê·¸ëŸ¬ë‚˜ íš¨ê³¼ëŠ” êµ¬ë¦¼.

**3) Other Conditional Pretraining Tasks**
  - RTD(Conditional binary difference prediction loss) ëŒ€ì‹  Conditional MLMì´ë‚˜ Corrective LMì„ ì‚¬ìš©í–ˆìœ¼ë‚˜ ì„±ëŠ¥ì€ êµ¬ë¦¼
  - êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–»ê²Œ ì ìš©í–ˆëŠì§€ì— ëŒ€í•œ ì„¤ëª…ì€ ë¶€ì¡±í•¨

**4) Insert/Delete**
  - ì›ë˜ í† í°ì„ ë‹¤ë¥¸ í† í°ìœ¼ë¡œ replaceí•˜ëŠ” ë°©ì‹ ëŒ€ì‹  ë‹¤ë¥¸ augmentation ë°©ì‹ ì‚¬ìš©
  - Insert : ì›ë˜ ë¬¸ì¥ ê¸¸ì´ì˜ 15% ì˜ tokenì„ insertí•œ ë’¤(generator ì´ìš©), insertëœ í† í°ì¸ì§€ ì›ë˜ ìˆë˜ í† í°ì¸ì§€ íŒë³„
  - Delete : ì›ë˜ í† í° ì¤‘ 15%ë¥¼ ì§€ìš´ ë’¤, ë‚¨ì•„ ìˆëŠ” ê° í† í°ì— ëŒ€í•˜ì—¬ ì´ì–´ì§€ëŠ” í† í°ì´ ì§€ì›Œì¡ŒëŠ”ì§€ ì•„ë‹Œì§€ íŒë³„
  - ê·¸ëŸ¬ë‚˜ ëª¨ë‘ ê²°ê³¼ëŠ” ì¢‹ì§€ ì•Šì•˜ìŒ.
 
**5) Pooler Choice**
  - SimCSEëŠ” BERTì™€ ë™ì¼í•œ pooler(one linear layer with tanh activation function)ë¥¼ ì‚¬ìš©í–ˆì§€ë§Œ, ì‹¤í—˜ í•´ë³´ë‹ˆ 2layer+batch normì´ ë” ì¢‹ì•˜ìŒ.
  - ì´ê±´ Computer Visionìª½ì—ì„œëŠ” í”í•˜ê²Œ ì‚¬ìš©ë˜ëŠ” ë°©ì‹ì„.
  - **BatchNormì„ ì¶”ê°€í•˜ëŠ” ë°©ì‹ì€ SimCSE, DiffCSE ëª¨ë‘ì—ì„œ ì¢‹ì•˜ìŒ.**

# Analysis
- SimCSEì™€ DiffCSEê°€ ì ìˆ˜ëŠ” ë‹¹ì—°íˆ DiffCSEê°€ ì¢‹ì§€ë§Œ ì •ì„±ì ì¸ ê²°ê³¼ëŠ” ì–´ë–»ê²Œ ë‹¤ë¥¸ì§€ ë¹„êµ
  - "You can do it, too."ì™€ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì¥ì„ 2000ì—¬ê°œ ì¤‘ì— ì°¾ì•„ë´
    - SimCSE: "you can use it, too."
    - DiffCSE: "You can do it, too." --> ì¦‰ ë¯¸ì„¸í•œ ì°¨ì´ë„ ë¶„ë³„í•´ì„œ ì •í™•í•œ ì •ë‹µì„ ì°¾ìŒ.
  - ![image](https://user-images.githubusercontent.com/18374514/167563909-86557a8c-77a8-4cdb-a779-fd2584fd5dfd.png)
- ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì¥ì„ ì°¾ëŠ” Retrieval Taskì—ì„œë„ DiffCSEê°€ ì••ë„í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ì„
  - ![image](https://user-images.githubusercontent.com/18374514/167564226-e72cd2e2-7589-48d2-b01b-40ff827b1fa8.png)
-  Distribution of Sentence Embedding
  - ![image](https://user-images.githubusercontent.com/18374514/167564325-ff440145-e9e4-4450-9fdd-cff31b702537.png)
  - Transformer base PLMì˜ ê²½ìš° representation spaceë¥¼ squeezeí•˜ëŠ” í˜„ìƒì´ ìˆëŠ”ë°, ìœ„ ê·¸ë¦¼ì—ì„œë„ DiffCSEê°€ ë‚´ë†“ëŠ” ì ìˆ˜ë“¤ì´ ì¢€ ëª°ë ¤ìˆëŠ” í˜„ìƒì´ ìˆìŒ.
  - ë”°ë¼ì„œ uniformity and alignment ë¥¼ ì²´í¬í•´ë³¸ ê²°ê³¼, SimCSEëŠ” uniformityì—ì„œ ì¥ì ì´ ìˆì§€ë§Œ DiffCSEëŠ” alignmentì—ì„œ ì¥ì ì´ ìˆìŒ.
  - It indicates that SimCSE and DiffCSE are optimizing the representation space in two different directions. And **the improvement of DiffCSE may come from its better alignment.**
  `UniformityëŠ” ë‹¨ì§€ ì „ì²´ dataì˜ representationì´ ì–¼ë§ˆë‚˜ í¼ì³ì ¸ ìˆëŠ”ì§€ë¥¼ ë³´ëŠ” ê±°ê³ , AlignmentëŠ” positve pairë¼ë¦¬ ì–¼ë§ˆë‚˜ ê°€ê¹Œì´ ë­‰ì³ì—¬ ìˆëŠ”ì§€ë¥¼ ë³´ëŠ” ê²ƒì´ê¸° ë•Œë¬¸ì— alignmentê°€ ë” ì–´ë–¤ taskë¥¼ ìˆ˜í–‰í•˜ëŠ”ë° ë„ì›€ì´ ë˜ì§€ ì•Šì„ê¹Œ í•˜ëŠ” ê°œì¸ì ì¸ ìƒê°`

# Conclusion
- DiffCSE ì œì•ˆ, unsupervised sentence embedding frame work, aware of, but not invariant to MLM based-word replacement 
- ì—¬ëŸ¬ ê²°ê³¼ì—ì„œ SimCSEë³´ë‹¤ ì¢‹ì€ ê²°ê³¼ë¥¼ ë³´ì„

# Take Home Messages ğŸ¤”
- Invariant, Equivariant CLì— ëŒ€í•œ ì´í•´ ì¤‘ìš”
- Conditional ELECTRA ê°œë…ì´ ë§¤ìš° í¥ë¯¸ë¡œì› ìŒ
- DiffCSEê°€ ì„±ëŠ¥ì´ ì¢‹ê¸´í•œë°, í•™ìŠµí• ë•Œ 3ê°€ì§€ ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ë„ì–´ë†“ê³  í•™ìŠµí•´ì•¼í•˜ë¯€ë¡œ ë¹„íš¨ìœ¨ì ì¸ë“¯..? STS ê²°ê³¼ëŠ” DCPCSEë‘ ë¹„ìŠ·í•˜ì§€ë§Œ í›¨ì”¬ ë©”ëª¨ë¦¬ê°€ ë§ì´ ë¨¹ëŠ”ë‹¤.
- Poolerì— BatchNormì„ ì“°ëŠ”ê±°ëŠ” êµ¿êµ¿

# Reference
- DiffCSE : https://arxiv.org/abs/2204.10298
- Equivariant CL : https://arxiv.org/abs/2111.00899
- SimCSE : https://arxiv.org/abs/2104.08821
