---
layout: post
date: 2023-08-05 14:08
created_date: 2023-08-05 14:08
title: "[paper] Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback"
description: Anthropic RLHF paper
comments: true
mathjax: true
category:
- Paper
tags:
- Anthropic
- ChatGPT
- RLHF
---

Anthropic's RLHF
<!--more-->

<!-- <mark style='background-color:pink'> -->
<style>
r{color:Red}
o{color:Orange}
g{color:Green}
</style>

# Abstract
